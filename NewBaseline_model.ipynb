{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Baseline Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal here is to read in the data for each file in the data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jehun\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\jehun\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\jehun\\Anaconda3\\lib\\site-packages\\sklearn\\lda.py:6: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "C:\\Users\\jehun\\Anaconda3\\lib\\site-packages\\sklearn\\learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\jehun\\Anaconda3\\lib\\site-packages\\sklearn\\qda.py:6: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn import *\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = 'D:\\Backups\\KaggleJul2017\\TSA'\n",
    "APS_FILE_NAME = 'D:\\\\Backups\\\\KaggleJul2017\\\\TSA\\\\stage1_aps.tar\\\\0a27d19c6ec397661b09f7d5998e0b14.aps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n",
      "adc_max_voltage -> [ 1.10000002]\n",
      "adc_min_voltage -> [-1.10000002]\n",
      "adc_type -> [17]\n",
      "ahis_software_version -> [ 7.0999999]\n",
      "avg_data_value -> [ 3190.42041016]\n",
      "azimuth_offset_angle -> [ 0.]\n",
      "band_width -> [ 30058.70898438]\n",
      "comments1 -> b'                                                                                '\n",
      "comments2 -> b'                                                                                '\n",
      "config_type -> [2]\n",
      "data_scale_factor -> [  1.80140702e-08]\n",
      "data_storage_order -> [9]\n",
      "data_type -> [5]\n",
      "data_units -> [0]\n",
      "date_modified -> b''\n",
      "date_processed -> b''\n",
      "depth_recon -> [ 0.]\n",
      "edge_weighting -> [0]\n",
      "elevation_offset_angle -> [ 0.]\n",
      "energy_type -> [2]\n",
      "file_type -> [12]\n",
      "filename -> b'                    '\n",
      "frequency -> [ 25000.]\n",
      "mat_velocity -> [  3.00000000e+08]\n",
      "max_data_value -> [ 65535.]\n",
      "min_data_value -> [ 0.]\n",
      "num_polarization_channels -> [1]\n",
      "num_pts -> [1]\n",
      "num_t_pts -> [16]\n",
      "num_x_pts -> [512]\n",
      "num_y_pts -> [660]\n",
      "num_z_pts -> [1]\n",
      "parent_filename -> b'                    '\n",
      "polarization_type -> [7 0 0 0]\n",
      "range_gate_end -> [ 1.13]\n",
      "range_gate_start -> [ 0.13]\n",
      "record_header_size -> [0]\n",
      "roll_offset_angle -> [ 0.]\n",
      "scan_direction -> [1]\n",
      "scan_orientation -> [0]\n",
      "scan_type -> [2]\n",
      "scanner_radius -> [ 0.63]\n",
      "scanner_type -> [31]\n",
      "spare00 -> [18184]\n",
      "spare01 -> [0 0 0 0 0]\n",
      "spare02 -> [0]\n",
      "spare06 -> [0]\n",
      "spare_end -> [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   2.82860979e-38   2.88371698e-38   3.04903264e-38\n",
      "   3.83880838e-38   3.06739890e-38]\n",
      "surf_removal -> [0]\n",
      "t_delay -> [ 0.]\n",
      "t_inc -> [ 22.5]\n",
      "t_units -> [4]\n",
      "time_processed -> b''\n",
      "trans_type -> [7]\n",
      "word_precision -> [16]\n",
      "word_type -> [4]\n",
      "x_acc -> [ 0.166667]\n",
      "x_encoder_res -> [ 88922.6640625]\n",
      "x_inc -> [ 0.00195312]\n",
      "x_max_travel -> [ 1.27777779]\n",
      "x_motor_res -> [ 720000.]\n",
      "x_offset -> [-0.5]\n",
      "x_return_speed -> [ 0.15277778]\n",
      "x_speed -> [ 0.166667]\n",
      "x_units -> [1]\n",
      "y_acc -> [ 0.]\n",
      "y_encoder_res -> [ 0.]\n",
      "y_inc -> [ 0.003175]\n",
      "y_max_travel -> [ 0.]\n",
      "y_motor_res -> [ 0.]\n",
      "y_offset -> [ 0.]\n",
      "y_return_speed -> [ 0.]\n",
      "y_speed -> [ 0.]\n",
      "y_units -> [1]\n",
      "z_acc -> [ 0.]\n",
      "z_encoder_res -> [ 0.]\n",
      "z_inc -> [ 0.]\n",
      "z_max_travel -> [ 0.]\n",
      "z_motor_res -> [ 0.]\n",
      "z_offset -> [ 0.]\n",
      "z_return_speed -> [ 0.]\n",
      "z_speed -> [ 0.]\n",
      "z_units -> [1]\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------------\n",
    "# read_header(infile):  takes an aps file and creates a dict of the data\n",
    "#\n",
    "# infile:               an aps file\n",
    "#\n",
    "# returns:              all of the fields in the header\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "def read_header(infile):\n",
    "    # declare dictionary\n",
    "    h = dict()\n",
    "    \n",
    "    with open(infile, 'r+b') as fid:\n",
    "\n",
    "        h['filename'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 20))\n",
    "        h['parent_filename'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 20))\n",
    "        h['comments1'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 80))\n",
    "        h['comments2'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 80))\n",
    "        h['energy_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "        h['config_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "        h['file_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "        h['trans_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "        h['scan_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "        h['data_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "        h['date_modified'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 16))\n",
    "        h['frequency'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['mat_velocity'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['num_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "        h['num_polarization_channels'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "        h['spare00'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "        h['adc_min_voltage'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['adc_max_voltage'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['band_width'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['spare01'] = np.fromfile(fid, dtype = np.int16, count = 5)\n",
    "        h['polarization_type'] = np.fromfile(fid, dtype = np.int16, count = 4)\n",
    "        h['record_header_size'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "        h['word_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "        h['word_precision'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "        h['min_data_value'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['max_data_value'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['avg_data_value'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['data_scale_factor'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['data_units'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "        h['surf_removal'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "        h['edge_weighting'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "        h['x_units'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "        h['y_units'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "        h['z_units'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "        h['t_units'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "        h['spare02'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "        h['x_return_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['y_return_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['z_return_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['scan_orientation'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "        h['scan_direction'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "        h['data_storage_order'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "        h['scanner_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "        h['x_inc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['y_inc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['z_inc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['t_inc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['num_x_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "        h['num_y_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "        h['num_z_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "        h['num_t_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "        h['x_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['y_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['z_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['x_acc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['y_acc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['z_acc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['x_motor_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['y_motor_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['z_motor_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['x_encoder_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['y_encoder_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['z_encoder_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['date_processed'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 8))\n",
    "        h['time_processed'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 8))\n",
    "        h['depth_recon'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['x_max_travel'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['y_max_travel'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['elevation_offset_angle'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['roll_offset_angle'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['z_max_travel'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['azimuth_offset_angle'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['adc_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "        h['spare06'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "        h['scanner_radius'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['x_offset'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['y_offset'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['z_offset'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['t_delay'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['range_gate_start'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['range_gate_end'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['ahis_software_version'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "        h['spare_end'] = np.fromfile(fid, dtype = np.float32, count = 10)\n",
    "\n",
    "    return h\n",
    "  \n",
    "#unit test ----------------------------------\n",
    "header = read_header(APS_FILE_NAME)\n",
    "print(len(header))\n",
    "\n",
    "for data_item in sorted(header):\n",
    "    print ('{} -> {}'.format(data_item, header[data_item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.ScanData'>\n",
      "(512, 660, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[  4.91784112e-06,   4.89982722e-06,   5.83655856e-06, ...,\n",
       "           4.82777068e-06,   5.33216462e-06,   5.29613681e-06],\n",
       "        [  5.13400983e-06,   4.53954590e-06,   4.71968633e-06, ...,\n",
       "           4.59358807e-06,   5.63840376e-06,   6.07074162e-06],\n",
       "        [  4.16125022e-06,   4.39543328e-06,   4.68365806e-06, ...,\n",
       "           4.73770069e-06,   5.18805246e-06,   4.57557371e-06],\n",
       "        ..., \n",
       "        [  6.07074162e-06,   6.34095250e-06,   4.48550327e-06, ...,\n",
       "           3.99912369e-06,   4.32337674e-06,   5.80053074e-06],\n",
       "        [  5.09798201e-06,   5.40422116e-06,   4.62961589e-06, ...,\n",
       "           4.25132066e-06,   3.90905325e-06,   5.51230551e-06],\n",
       "        [  5.17003809e-06,   4.64763025e-06,   3.80096890e-06, ...,\n",
       "           3.78295476e-06,   4.62961589e-06,   4.89982722e-06]],\n",
       "\n",
       "       [[  5.07996765e-06,   4.91784112e-06,   5.17003809e-06, ...,\n",
       "           6.46705121e-06,   4.28734893e-06,   5.69244639e-06],\n",
       "        [  7.06151559e-06,   5.49429160e-06,   6.59314992e-06, ...,\n",
       "           5.63840376e-06,   5.35017898e-06,   5.04393984e-06],\n",
       "        [  4.79174287e-06,   4.48550327e-06,   5.17003809e-06, ...,\n",
       "           4.14323631e-06,   5.00791157e-06,   4.28734893e-06],\n",
       "        ..., \n",
       "        [  5.58436159e-06,   5.74648857e-06,   4.50351763e-06, ...,\n",
       "           3.54877193e-06,   5.17003809e-06,   4.61160198e-06],\n",
       "        [  5.02592547e-06,   5.17003809e-06,   4.39543328e-06, ...,\n",
       "           4.21529239e-06,   5.00791157e-06,   4.28734893e-06],\n",
       "        [  5.65641812e-06,   6.05272771e-06,   3.99912369e-06, ...,\n",
       "           3.80096890e-06,   4.23330630e-06,   4.50351763e-06]],\n",
       "\n",
       "       [[  5.29613681e-06,   6.48506511e-06,   5.63840376e-06, ...,\n",
       "           6.01669944e-06,   5.15202419e-06,   5.62038986e-06],\n",
       "        [  5.80053074e-06,   5.04393984e-06,   5.92662900e-06, ...,\n",
       "           4.98989766e-06,   6.32293859e-06,   5.98067118e-06],\n",
       "        [  5.15202419e-06,   4.71968633e-06,   5.80053074e-06, ...,\n",
       "           3.92706716e-06,   5.62038986e-06,   5.31415071e-06],\n",
       "        ..., \n",
       "        [  4.32337674e-06,   5.74648857e-06,   4.80975677e-06, ...,\n",
       "           3.69288432e-06,   4.70167242e-06,   5.04393984e-06],\n",
       "        [  5.17003809e-06,   5.17003809e-06,   4.97188330e-06, ...,\n",
       "           4.21529239e-06,   4.59358807e-06,   5.04393984e-06],\n",
       "        [  5.45826333e-06,   4.97188330e-06,   4.17926412e-06, ...,\n",
       "           3.53075779e-06,   4.55755981e-06,   4.37741892e-06]],\n",
       "\n",
       "       ..., \n",
       "       [[  5.87258683e-06,   5.02592547e-06,   6.37698076e-06, ...,\n",
       "           6.71924818e-06,   4.73770069e-06,   5.36819289e-06],\n",
       "        [  5.07996765e-06,   6.43102294e-06,   5.38620679e-06, ...,\n",
       "           5.33216462e-06,   5.89060119e-06,   4.71968633e-06],\n",
       "        [  4.97188330e-06,   4.10720804e-06,   4.14323631e-06, ...,\n",
       "           5.72847421e-06,   6.19684033e-06,   4.95386939e-06],\n",
       "        ..., \n",
       "        [  5.18805246e-06,   4.59358807e-06,   5.29613681e-06, ...,\n",
       "           3.51274366e-06,   4.41344719e-06,   5.11599592e-06],\n",
       "        [  4.61160198e-06,   4.44947545e-06,   5.11599592e-06, ...,\n",
       "           3.67487041e-06,   6.26889641e-06,   4.14323631e-06],\n",
       "        [  4.39543328e-06,   4.61160198e-06,   4.39543328e-06, ...,\n",
       "           4.34139110e-06,   4.71968633e-06,   5.18805246e-06]],\n",
       "\n",
       "       [[  4.75571460e-06,   5.24209463e-06,   6.93541688e-06, ...,\n",
       "           4.70167242e-06,   4.34139110e-06,   4.79174287e-06],\n",
       "        [  4.62961589e-06,   5.71046030e-06,   7.78207868e-06, ...,\n",
       "           5.49429160e-06,   5.87258683e-06,   5.22408027e-06],\n",
       "        [  4.75571460e-06,   4.91784112e-06,   5.31415071e-06, ...,\n",
       "           4.14323631e-06,   4.21529239e-06,   4.53954590e-06],\n",
       "        ..., \n",
       "        [  4.37741892e-06,   4.61160198e-06,   5.13400983e-06, ...,\n",
       "           3.76494063e-06,   5.02592547e-06,   5.49429160e-06],\n",
       "        [  5.36819289e-06,   4.79174287e-06,   4.79174287e-06, ...,\n",
       "           3.45870149e-06,   5.42223506e-06,   4.55755981e-06],\n",
       "        [  4.70167242e-06,   5.45826333e-06,   5.35017898e-06, ...,\n",
       "           4.26933457e-06,   5.24209463e-06,   4.62961589e-06]],\n",
       "\n",
       "       [[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        ..., \n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00]]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------------\n",
    "# read_data(infile):  reads and rescales any of the four image types\n",
    "#\n",
    "# infile:             an .aps, .aps3d, .a3d, or ahi file\n",
    "#\n",
    "# returns:            the stack of images\n",
    "#\n",
    "# note:               word_type == 7 is an np.float32, word_type == 4 is np.uint16      \n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "from collections import namedtuple\n",
    "from warnings import warn\n",
    "\n",
    "ScanData = namedtuple('ScanData', ['header', 'data', 'real', 'imag', 'extension'])\n",
    "print(ScanData)\n",
    "\n",
    "def read_data(infile):\n",
    "    \"\"\"Read any of the 4 types of image files, returns a numpy array of the image contents\n",
    "    \"\"\"\n",
    "    _, extension = os.path.splitext(infile)\n",
    "    sd_dict = {'header': None, 'data': None, 'real': None, 'imag': None, 'extension': extension}\n",
    "    \n",
    "    h = read_header(infile)\n",
    "    sd_dict['header'] = h\n",
    "    nx = int(h['num_x_pts'])\n",
    "    ny = int(h['num_y_pts'])\n",
    "    nt = int(h['num_t_pts'])\n",
    "    with open(infile, 'rb') as fid:\n",
    "        fid.seek(512) #skip header\n",
    "        if extension == '.aps' or extension == '.a3daps':\n",
    "            if(h['word_type']==7): #float32\n",
    "                data = np.fromfile(fid, dtype = np.float32, count = nx * ny * nt)\n",
    "            elif(h['word_type']==4): #uint16\n",
    "                data = np.fromfile(fid, dtype = np.uint16, count = nx * ny * nt)\n",
    "            data = data * h['data_scale_factor'] #scaling factor\n",
    "            data = data.reshape(nx, ny, nt, order='F').copy() #make N-d image\n",
    "        elif extension == '.a3d':\n",
    "            if(h['word_type']==7): #float32\n",
    "                data = np.fromfile(fid, dtype = np.float32, count = nx * ny * nt)\n",
    "            elif(h['word_type']==4): #uint16\n",
    "                data = np.fromfile(fid, dtype = np.uint16, count = nx * ny * nt)\n",
    "            data = data * h['data_scale_factor'] #scaling factor\n",
    "            data = data.reshape(nx, nt, ny, order='F').copy() #make N-d image\n",
    "        elif extension == '.ahi':\n",
    "            data = np.fromfile(fid, dtype = np.float32, count = 2* nx * ny * nt)\n",
    "            data = data.reshape(2, ny, nx, nt, order='F').copy()\n",
    "            real = data[0,:,:,:].copy()\n",
    "            imag = data[1,:,:,:].copy()\n",
    "            sd_dict['real'] = real\n",
    "            sd_dict['imag'] = imag\n",
    "        else:\n",
    "            warn('Extension not really supported: {}'.format(extension), RuntimeWarning)\n",
    "            data = None\n",
    "        sd_dict['data'] = data\n",
    "        \n",
    "    #return ScanData(**sd_dict)\n",
    "    return sd_dict\n",
    "\n",
    "#unit test ----------------------------------\n",
    "d = read_data(APS_FILE_NAME)\n",
    "print(d['data'].shape)\n",
    "d['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "label_df = pd.read_csv(os.path.join(base_dir, 'stage1_labels.csv'))\n",
    "label_df['ImageId'] = label_df['Id'].map(lambda x: x.split('_')[0])\n",
    "label_df['ImageZoneId'] = label_df['Id'].map(lambda x: int(x.split('_')[1][4:]))\n",
    "# create a vector with each category being an image zone\n",
    "label_df['ImageZoneVec'] = label_df.apply(\n",
    "    lambda c_row:[c_row['Probability']*to_categorical(c_row['ImageZoneId']-1, \n",
    "                                                      num_classes = label_df['ImageZoneId'].max())],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Probability</th>\n",
       "      <th>ImageId</th>\n",
       "      <th>ImageZoneId</th>\n",
       "      <th>ImageZoneVec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00360f79fd6e02781457eda48f85da90_Zone1</td>\n",
       "      <td>0</td>\n",
       "      <td>00360f79fd6e02781457eda48f85da90</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00360f79fd6e02781457eda48f85da90_Zone10</td>\n",
       "      <td>0</td>\n",
       "      <td>00360f79fd6e02781457eda48f85da90</td>\n",
       "      <td>10</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00360f79fd6e02781457eda48f85da90_Zone11</td>\n",
       "      <td>0</td>\n",
       "      <td>00360f79fd6e02781457eda48f85da90</td>\n",
       "      <td>11</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00360f79fd6e02781457eda48f85da90_Zone12</td>\n",
       "      <td>0</td>\n",
       "      <td>00360f79fd6e02781457eda48f85da90</td>\n",
       "      <td>12</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00360f79fd6e02781457eda48f85da90_Zone13</td>\n",
       "      <td>0</td>\n",
       "      <td>00360f79fd6e02781457eda48f85da90</td>\n",
       "      <td>13</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Id  Probability  \\\n",
       "0   00360f79fd6e02781457eda48f85da90_Zone1            0   \n",
       "1  00360f79fd6e02781457eda48f85da90_Zone10            0   \n",
       "2  00360f79fd6e02781457eda48f85da90_Zone11            0   \n",
       "3  00360f79fd6e02781457eda48f85da90_Zone12            0   \n",
       "4  00360f79fd6e02781457eda48f85da90_Zone13            0   \n",
       "\n",
       "                            ImageId  ImageZoneId  \\\n",
       "0  00360f79fd6e02781457eda48f85da90            1   \n",
       "1  00360f79fd6e02781457eda48f85da90           10   \n",
       "2  00360f79fd6e02781457eda48f85da90           11   \n",
       "3  00360f79fd6e02781457eda48f85da90           12   \n",
       "4  00360f79fd6e02781457eda48f85da90           13   \n",
       "\n",
       "                                        ImageZoneVec  \n",
       "0  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "1  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "2  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "3  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "4  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ff9c9b7de5dacc8315e2bbc18c451c49_Zone6'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.Id[19478]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.ImageZoneVec[19478][0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19499,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.ImageZoneVec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Additional processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.aps` version of the scans are images (sometimes refered to herein also as slices) with views from shots taken at a regular interval of $22.5$-degree rotation, $360$ degrees around the subject scanned. So for each subject, we'll get $16$ scans. Each scan will contain a view from a given angle of any visible threat zones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Part of my approach (inspire by Brian Farrar) in this notebook is to isolate each individual threat zone from every visible angle. Later, I want to be able to make features out of each individual threat zone from each angle that a given threat zone is visible. That will allow me to later train on each threat zone individually from every view in a 2D format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is done by dividing a full image into sectors - this will enable me to isolate each threat zone (there are 16 threat zones). Note that each image is $512$ X $660$ pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
